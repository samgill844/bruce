{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9847369",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e19f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bruce, numpy as np, matplotlib.pyplot as plt, os\n",
    "from astropy.table import Table, Column\n",
    "from astropy.stats import sigma_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0606724",
   "metadata": {},
   "source": [
    "# Load the tics\n",
    "\n",
    "Data should have the form of (ascii or CSV, your choice). t_zero is in full BJD, width is in days, depth is in normalised flux. If you ue SPOCFIT, if you fit a single transit you will see 3 reported values on the bottom row which are these values for each event (t_zero, width, depth).\n",
    "\n",
    "tic_id,\tt_zero_1,\twidth_1,\tdepth_1,\tt_zero_2,\twidth_2,\tdepth_2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebbe077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TIC ID  Linked TIC ID ...   tic_id \n",
      "--------- ------------- ... ---------\n",
      "  7145074       7145074 ...   7145074\n",
      " 20904104      20904104 ...  20904104\n",
      " 22317640      22317640 ...  22317640\n",
      " 32179255      32179255 ...  32179255\n",
      " 37117064      37117064 ...  37117064\n",
      " 42428568      42428568 ...  42428568\n",
      " 49066806      49066806 ...  49066806\n",
      "      ...           ... ...       ...\n",
      " 39904176      39904176 ...  39904176\n",
      "207501148     207501148 ... 207501148\n",
      "116261487     116261487 ... 116261487\n",
      "  5267885       5267885 ...   5267885\n",
      "275267824     275267824 ... 275267824\n",
      "286969201     286969201 ... 286969201\n",
      "103095888     103095888 ... 103095888\n",
      "Length = 97 rows\n"
     ]
    }
   ],
   "source": [
    "duos = Table.read('duos.csv')\n",
    "duos['tic_id'] = duos['TIC ID']\n",
    "print(duos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae682c",
   "metadata": {},
   "source": [
    "# Now the main worker function\n",
    "\n",
    "This function does the following:\n",
    "-  Load the latest TESS data\n",
    "-  Flatten the lightcurve\n",
    "-  Fit the events\n",
    "-  Calcualte the aliases\n",
    "-  Plot the permissable aliases\n",
    "-  Create a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e4891b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      "ðŸ“‚ Download directory: /var/folders/fs/c4gpqhmx5tbcbsv_cbs0yhn80000gn/T/tmpiaxrww9m\n",
      "\n",
      "Querying TIC 5267885 from MAST...\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HLSP/tess-spoc/s0026/target/0000/0000/0526/7885/hlsp_tess-spoc_tess_phot_0000000005267885-s0026_tess_v1_lc.fits to ./mastDownload/HLSP/hlsp_tess-spoc_tess_phot_0000000005267885-s0026_tess_v1_tp/hlsp_tess-spoc_tess_phot_0000000005267885-s0026_tess_v1_lc.fits ... [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD - 2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'e-/s' did not parse as fits unit: At col 0, Unit 'e' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'pixels' did not parse as fits unit: At col 0, Unit 'pixels' not supported by the FITS standard. Did you mean pixel? If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HLSP/tess-spoc/s0053/target/0000/0000/0526/7885/hlsp_tess-spoc_tess_phot_0000000005267885-s0053_tess_v1_lc.fits to ./mastDownload/HLSP/hlsp_tess-spoc_tess_phot_0000000005267885-s0053_tess_v1_tp/hlsp_tess-spoc_tess_phot_0000000005267885-s0053_tess_v1_lc.fits ... [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD - 2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'e-/s' did not parse as fits unit: At col 0, Unit 'e' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'pixels' did not parse as fits unit: At col 0, Unit 'pixels' not supported by the FITS standard. Did you mean pixel? If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HLSP/qlp/s0079/0000/0000/0526/7885/hlsp_qlp_tess_ffi_s0079-0000000005267885_tess_v02_llc.fits to ./mastDownload/HLSP/hlsp_qlp_tess_ffi_s0079-0000000005267885_tess_v02_llc/hlsp_qlp_tess_ffi_s0079-0000000005267885_tess_v02_llc.fits ... [Done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD-2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HLSP/qlp/s0080/0000/0000/0526/7885/hlsp_qlp_tess_ffi_s0080-0000000005267885_tess_v01_llc.fits to ./mastDownload/HLSP/hlsp_qlp_tess_ffi_s0080-0000000005267885_tess_v01_llc/hlsp_qlp_tess_ffi_s0080-0000000005267885_tess_v01_llc.fits ... [Done]\n",
      "\n",
      "âœ… Download summary:\n",
      "Sector ...\n",
      "------ ...\n",
      "    26 ...\n",
      "    53 ...\n",
      "    79 ...\n",
      "    80 ...\n",
      "\n",
      "Temporary data stored in: /var/folders/fs/c4gpqhmx5tbcbsv_cbs0yhn80000gn/T/tmpiaxrww9m\n",
      "This directory will be deleted when the program exits.\n",
      "W :  143\n",
      "W :  144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD-2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W :  144\n",
      "W :  144\n",
      "W :  144\n",
      "W :  144\n",
      "W :  144\n",
      "W :  106\n",
      "W :  144\n",
      "W :  16\n",
      "W :  106\n",
      "W :  144\n",
      "W :  144\n",
      "W :  144\n",
      "W :  144\n",
      "Initial Chi-Sqaured : 535.24 [red 16.22]\n",
      "Fitted parameters for TIC-5267885:\n",
      "t_zero : 2459012.4474786143\n",
      "radius_1 : 0.014215468348660165\n",
      "k : 0.2023608031463896\n",
      "b : 0.7073743144618813\n",
      "Final Chi-Sqaured : 37.81 [red 1.15]\n",
      "Initial Chi-Sqaured : 636.13 [red 30.29]\n",
      "Fitted parameters for TIC-5267885:\n",
      "t_zero : 2459763.1438184087\n",
      "radius_1 : 0.01700411426882764\n",
      "k : 0.1984598485832897\n",
      "b : 0.7701300608300163\n",
      "Final Chi-Sqaured : 218.47 [red 10.40]\n",
      "1 51 1 50.046422652962306 750.6963397944346 15 15.013926795888692\n",
      "0 0.0\n",
      "1 0.0\n",
      "2 0.0\n",
      "3 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n",
      "9 0.0\n",
      "10 0.0\n",
      "11 0.0\n",
      "12 0.0\n",
      "13 0.0\n",
      "14 0.0\n",
      "15 0.0\n",
      "16 0.0\n",
      "17 0.0\n",
      "18 0.0\n",
      "19 0.0\n",
      "20 0.0\n",
      "21 0.0\n",
      "22 0.0\n",
      "23 0.0\n",
      "24 0.0\n",
      "25 0.0\n",
      "26 0.0\n",
      "27 0.0\n",
      "28 0.0\n",
      "29 0.0\n",
      "30 0.0\n",
      "31 0.0\n",
      "32 0.0\n",
      "33 -1740.2394967220064\n",
      "34 -1390.9305133972318\n",
      "35 -1403.832154677081\n",
      "36 -1440.0681357932133\n",
      "37 -1374.736978117333\n",
      "38 -1387.326548246561\n",
      "39 -9210.37413684184\n",
      "40 -54250.62455448628\n",
      "41 -11703.162824877252\n",
      "42 -11044.348378492408\n",
      "43 -4163.1791907909\n",
      "44 -12206.105665017447\n",
      "45 -12260.282138231447\n",
      "46 -3914.9164717412677\n",
      "47 -12836.195542319903\n",
      "48 -17005.931585142887\n",
      "49 -9380.792449230403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  7.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(duos))[:]:\n",
    "    if duos['tic_id'][i]!=5267885 : continue\n",
    "    print(5267885 in duos['tic_id'])\n",
    "    \n",
    "    # Create the output dir (we'll use this as cache for the data too)\n",
    "    output_dir = os.getcwd() + '/{:}'.format(duos['tic_id'][i])\n",
    "    os.system('mkdir -p {:}'.format(output_dir))\n",
    "    #if os.path.isfile(output_dir + '/' + 'TIC-{:}_ALIASES.png'.format(duos['tic_id'][i])) : continue\n",
    "\n",
    "    # Now load the TESS data (SPOC, QLP)\n",
    "    # We are not making our own here like TESSTPF, not yet anyway...\n",
    "    # for data_type\n",
    "    #   single_product -> all sectors together\n",
    "    #   per_sector -> list of per-sector lightcurves\n",
    "    #   northern_duos -> YEARS 2 and 4, then a list of other sectors \n",
    "    #   southern -> YEARS 1 and 3, then a list of other sectors (NOT IMPLEMENTED YET) \n",
    "    t, data,data_labels, base_dir =  bruce.ambiguous_period.download_tess_data(duos['tic_id'][i], \n",
    "                                                              max_sector=None, \n",
    "                                                                   use_ffi=True, \n",
    "                                                                   download_dir=None, \n",
    "                                                                   bin_length=0.5/24)\n",
    "    \n",
    "    # Now flatten the data\n",
    "    for j, k in zip(data, data_labels):\n",
    "        # Flatten the data by SG filter, we need an odd kernel legth based on cadence\n",
    "        j.flatten_data_old(window_width=3, sigmaclip=3, dx_lim=0.1)\n",
    "\n",
    "\n",
    "#         for seg in bruce.data.find_nights_from_data(j.time, dx_lim=0.2):\n",
    "#             j.w = np.ones(j.time.shape[0])*np.median(j.flux)\n",
    "\n",
    "        # Optinally save the data\n",
    "        j.write_data(output_dir + '/' +'TESS_DATA_{:}.txt'.format(k))\n",
    "        fig, ax = j.plot_segments(dx_lim=0.5)\n",
    "        fig.savefig(output_dir + '/' + 'TESS_DATA_{:}.png'.format(k))\n",
    "        plt.close(fig)\n",
    "\n",
    "    # # Now re-order_datasets based on epochs given\n",
    "    # We will unpack now, (data with transits, and data without)\n",
    "    # We may need to change this for it to work properly (Sam is working on it)\n",
    "    # Its worth noting we can incorparate ground based data here too\n",
    "    # data_from_ground = bruce.ambiguous_period.mono_event.photometry_time_series(time, flux, flux_err, w = norm_model)\n",
    "    # Then this can go in data_other_sectors\n",
    "    data, data_labels = bruce.ambiguous_period.group_data_by_epochs(data, data_labels, duos['t_zero_1'][i], duos['t_zero_2'][i])\n",
    "    data, data_other_sectors = data[0], data[1:]\n",
    "\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # FIT EVENT 1\n",
    "    ############################\n",
    "    # Mask data and create the mono_event object\n",
    "    nmask = 3\n",
    "    mask1 = (data.time > (duos['t_zero_1'][i] - nmask*duos['width_1'][i])) &  (data.time < (duos['t_zero_1'][i] + nmask*duos['width_1'][i]))\n",
    "    data_event_1 = bruce.ambiguous_period.photometry_time_series(data.time[mask1], data.flux[mask1], data.flux_err[mask1], w=data.w[mask1]) #np.percentile(data.flux[mask1], 50)*np.ones(data.time[mask1].shape[0])\n",
    "    m1 = bruce.ambiguous_period.mono_event(duos['t_zero_1'][i], duos['width_1'][i], duos['depth_1'][i], data_event_1, name='TIC-{:}'.format(duos['tic_id'][i]), median_bin_size = None,convolve_bin_size = None)\n",
    "    \n",
    "    # Fit the event and report plots\n",
    "    fig_initial, ax_initial, fig_final, ax_final, return_data_1 = m1.fit_event_with_fixed_period(fit_period=30., plot=True, )\n",
    "    fig_initial.tight_layout()\n",
    "    fig_final.tight_layout()\n",
    "    fig_initial.savefig(output_dir + '/' + 'TIC-{:}_EVENT_1_INITIAL_INITIAL.png'.format(duos['tic_id'][i]))\n",
    "    fig_final.savefig(output_dir + '/' + 'TIC-{:}_EVENT_1_INITIAL_FINAL.png'.format(duos['tic_id'][i]))\n",
    "    plt.close(fig_initial); plt.close(fig_final)\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # FIT EVENT 2\n",
    "    ############################\n",
    "    # Mask data and create the mono_event object\n",
    "    mask2 = (data.time > (duos['t_zero_2'][i] - nmask*duos['width_2'][i])) &  (data.time < (duos['t_zero_2'][i] + nmask*duos['width_2'][i]))\n",
    "    data_event_2 = bruce.ambiguous_period.photometry_time_series(data.time[mask2], data.flux[mask2], data.flux_err[mask2], w=data.w[mask2]) #np.percentile(data.flux[mask2], 50)*np.ones(data.time[mask2].shape[0])\n",
    "    m2 = bruce.ambiguous_period.mono_event(duos['t_zero_2'][i], duos['width_2'][i], duos['depth_2'][i], data_event_2, name='TIC-{:}'.format(duos['tic_id'][i]), median_bin_size = None,convolve_bin_size = 3)\n",
    "\n",
    "    # Fit the event and report plots\n",
    "    fig_initial, ax_initial, fig_final, ax_final, return_data_2 = m2.fit_event_with_fixed_period(fit_period=30., plot=True, )\n",
    "    fig_initial.tight_layout()\n",
    "    fig_final.tight_layout()\n",
    "    fig_initial.savefig(output_dir + '/' + 'TIC-{:}_EVENT_2_INITIAL_INITIAL.png'.format(duos['tic_id'][i]))\n",
    "    fig_final.savefig(output_dir + '/' + 'TIC-{:}_EVENT_2_INITIAL_FINAL.png'.format(duos['tic_id'][i]))\n",
    "    plt.close(fig_initial); plt.close(fig_final)\n",
    "\n",
    "    # We are going to make a nice plot of the two events with their models\n",
    "    fig, ax = plt.subplots(1,2, gridspec_kw={'hspace' : 0, 'wspace' : 0}, figsize = (6.4, 3.8))\n",
    "    ax[0].errorbar(return_data_1[0], return_data_1[1], yerr=return_data_1[2], fmt='k.', alpha = 0.1)\n",
    "    ax[0].plot(return_data_1[3], return_data_1[4], c='orange')\n",
    "    ax[1].errorbar(return_data_2[0], return_data_2[1], yerr=return_data_2[2], fmt='k.', alpha = 0.1)\n",
    "    ax[1].plot(return_data_2[3], return_data_2[4], c='orange')\n",
    "    ax[1].set(yticks=[])\n",
    "    ylim1 = ax[0].get_ylim()\n",
    "    ylim2 = ax[1].get_ylim()\n",
    "    ylim = [min(ylim1[0],ylim2[0]), max(ylim1[1], ylim2[1])]\n",
    "    ax[0].set_ylim(ylim)\n",
    "    ax[1].set_ylim(ylim)\n",
    "    fig.supxlabel('Time from Transit [d]', fontsize=18, x=0.55, y = -0.005)\n",
    "    fig.supylabel('Flux', fontsize=18)\n",
    "    fig.suptitle(m2.name, y=0.95, x=0.55, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3', alpha=1.0), ha='center', fontsize=18)\n",
    "    plt.subplots_adjust(right=0.99, top=0.99, bottom=0.13)\n",
    "    fig.savefig(output_dir + '/' + 'TIC-{:}_BOTH_EVENTS.png'.format(duos['tic_id'][i]))\n",
    "    plt.close(fig)\n",
    "\n",
    "    ########################################################\n",
    "    # CREATE THE AMBIGUOUS PERIOD OBJECT\n",
    "    ########################################################\n",
    "    p = bruce.ambiguous_period.ambiguous_period(data, events=[m1,m2], name='TIC-{:}'.format(duos['tic_id'][i]),\n",
    "                        median_bin_size = 2,convolve_bin_size = 2)\n",
    "\n",
    "    # Now mask and filter \n",
    "    p.mask_and_filter_events()\n",
    "\n",
    "    # Calculate aliases\n",
    "    # Do not use nsolutions_events here (that is superceeded later)\n",
    "    nsolutions_events = p.calcualte_aliases(dx_lim=0.03, min_period=15)\n",
    "\n",
    "    # Now calcualte whether we saw a transit by comparing the model to a flat line\n",
    "    delta_L_data = p.calcualte_data_delta_L(data)\n",
    "    #delta_L_data = delta_L_data + 100 # THIS FUDGE IS OFTEN NEEDED\n",
    "    for j in range(delta_L_data.shape[0]):\n",
    "        print(j, delta_L_data[j])\n",
    "    delta_L_data_from_other_sectors_or_others = [p.calcualte_data_delta_L(j) for j in data_other_sectors]\n",
    "    p.delta_L = np.array([delta_L_data, *delta_L_data_from_other_sectors_or_others])\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    # Plot the aliases\n",
    "    ########################################################\n",
    "    fig, ax, alias_colours  = p.plot_aliases(phot_data=data_other_sectors, phot_data_labels=data_labels)\n",
    "    fig.savefig(output_dir + '/' + 'TIC-{:}_ALIASES.png'.format(duos['tic_id'][i]), dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    ########################################################\n",
    "    # Now report the aliases\n",
    "    ########################################################\n",
    "    aliases = (p.aliases)[alias_colours[:,-1]==alias_colours.max()]\n",
    "    periods = (p.max_period/p.aliases)[alias_colours[:,-1]==alias_colours.max()]\n",
    "    alaises = Table()\n",
    "    alaises.add_column(Column(m1.de_get_epoch()*np.ones(len(aliases)), name='t_zero_1'))\n",
    "    alaises.add_column(Column(m1.de_get_radius_1()*np.ones(len(aliases)), name='radius_1_1'))\n",
    "    alaises.add_column(Column(m1.de_get_k()*np.ones(len(aliases)), name='k_1'))\n",
    "    alaises.add_column(Column(m1.de_get_b()*np.ones(len(aliases)), name='b_1'))\n",
    "    alaises.add_column(Column(m1.de_transit_width()*np.ones(len(aliases)), name='width_1'))\n",
    "    alaises.add_column(Column(m2.de_get_epoch()*np.ones(len(aliases)), name='t_zero_2'))\n",
    "    alaises.add_column(Column(m2.de_get_radius_1()*np.ones(len(aliases)), name='radius_1_2'))\n",
    "    alaises.add_column(Column(m2.de_get_k()*np.ones(len(aliases)), name='k_2'))\n",
    "    alaises.add_column(Column(m2.de_get_b()*np.ones(len(aliases)), name='b_2'))\n",
    "    alaises.add_column(Column(m2.de_transit_width()*np.ones(len(aliases)), name='width_2'))\n",
    "    alaises.add_column(Column(aliases, name='alias'))\n",
    "    alaises.add_column(Column(periods, name='period'))\n",
    "    alaises.write(output_dir + '/' + 'TIC-{:}_ALIASES.fits'.format(duos['tic_id'][i]), overwrite=True)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1afb201",
   "metadata": {},
   "source": [
    "# Now lok for solved systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7a835e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49066806, 2459290.1263804263, 27.65127434802276\n",
      "289840544, 2458331.289873723, 25.930949741075263\n",
      "207501148, 2459007.727905593, 166.03730747115333\n",
      "145006304, 2458579.5012627575, 15.07637889701303\n",
      "142278054, 2458595.025455752, 26.493703934191554\n",
      "330799539, 2458918.306298589, 23.968420412857085\n",
      "209006017, 2459376.0885753254, 21.369980819701382\n",
      "437293313, 2458578.44183257, 24.98815684582417\n",
      "37117064, 2458483.095874101, 22.30350940712643\n",
      "287204963, 2458402.9369503283, 38.389474153837284\n",
      "276376289, 2458716.9436017587, 30.116887344526024\n",
      "170692379, 2458643.309522811, 31.282666421752978\n",
      "257024338, 2458922.4816428316, 81.43381791616169\n",
      "229476204, 2458743.521617817, 648.0597211997956\n",
      "270771827, 2458523.000238604, 20.439924176762695\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob('*/TIC-*_ALIASES.fits')\n",
    "\n",
    "os.system('mkdir -p solved_systems; rm solved_systems/*')\n",
    "\n",
    "for i in range(len(files)):\n",
    "    tic_id  = int(files[i].split('/')[0])\n",
    "    t = Table.read(files[i])\n",
    "    if len(t)==1:\n",
    "        os.system('cp {:}/TIC-{:}_ALIASES.png solved_systems'.format(tic_id,tic_id))\n",
    "        \n",
    "        print('{:}, {:}, {:}'.format(tic_id,  t['t_zero_1'][0], t['period'][0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809e76a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([734.80306314, 367.40153157, 244.93435438, 183.70076578,\n",
       "       146.96061263, 122.46717719, 104.97186616,  91.85038289,\n",
       "        81.64478479,  73.48030631,  66.80027847,  61.23358859,\n",
       "        56.52331255,  52.48593308,  48.98687088,  45.92519145,\n",
       "        43.2237096 ,  40.8223924 ,  38.67384543,  36.74015316,\n",
       "        34.99062205,  33.40013923,  31.94795927,  30.6167943 ,\n",
       "        29.39212253,  28.26165627,  27.21492826,  26.24296654,\n",
       "        25.33803666,  24.49343544,  23.70332462,  22.96259572,\n",
       "        22.26675949,  21.6118548 ,  20.99437323,  20.4111962 ,\n",
       "        19.85954225,  19.33692271,  18.84110418,  18.37007658,\n",
       "        17.92202593,  17.49531103,  17.08844333,  16.70006962,\n",
       "        16.32895696,  15.97397963,  15.63410773,  15.30839715])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7537eac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12027835950740756"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.de_transit_width()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca85204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
