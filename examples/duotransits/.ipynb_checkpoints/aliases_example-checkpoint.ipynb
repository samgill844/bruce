{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9847369",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e19f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bruce, numpy as np, matplotlib.pyplot as plt, os\n",
    "from astropy.table import Table\n",
    "from astropy.stats import sigma_clip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0606724",
   "metadata": {},
   "source": [
    "# Load the tics\n",
    "\n",
    "Data should have the form of (ascii or CSV, your choice). t_zero is in full BJD, width is in days, depth is in normalised flux. If you ue SPOCFIT, if you fit a single transit you will see 3 reported values on the bottom row which are these values for each event (t_zero, width, depth).\n",
    "\n",
    "tic_id,\tt_zero_1,\twidth_1,\tdepth_1,\tt_zero_2,\twidth_2,\tdepth_2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebbe077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tic_id       t_zero_1           width_1              depth_1             t_zero_2            width_2              depth_2       \n",
      "--------- ----------------- ------------------- --------------------- ------------------ ------------------- ---------------------\n",
      "402710280 2459384.609967493 0.21918118646434467 0.0021916840537857807 2460838.1862335913 0.21475029521033676 0.0007637497838969276\n"
     ]
    }
   ],
   "source": [
    "duos = Table.read('duos.csv')\n",
    "print(duos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae682c",
   "metadata": {},
   "source": [
    "# Now the main worker function\n",
    "\n",
    "This function does the following:\n",
    "-  Load the latest TESS data\n",
    "-  Flatten the lightcurve\n",
    "-  Fit the events\n",
    "-  Calcualte the aliases\n",
    "-  Plot the permissable aliases\n",
    "-  Create a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e4891b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found cached file /Users/sam/Software/bruce/examples/duotransits/402710280/mastDownload/HLSP/hlsp_tess-spoc_tess_phot_0000000402710280-s0012_tess_v1_tp/hlsp_tess-spoc_tess_phot_0000000402710280-s0012_tess_v1_lc.fits with expected size 164160. [astroquery.query]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD - 2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'e-/s' did not parse as fits unit: At col 0, Unit 'e' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'pixels' did not parse as fits unit: At col 0, Unit 'pixels' not supported by the FITS standard. Did you mean pixel? If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found cached file /Users/sam/Software/bruce/examples/duotransits/402710280/mastDownload/HLSP/hlsp_tess-spoc_tess_phot_0000000402710280-s0039_tess_v1_tp/hlsp_tess-spoc_tess_phot_0000000402710280-s0039_tess_v1_lc.fits with expected size 432000. [astroquery.query]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD - 2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'e-/s' did not parse as fits unit: At col 0, Unit 'e' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'pixels' did not parse as fits unit: At col 0, Unit 'pixels' not supported by the FITS standard. Did you mean pixel? If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found cached file /Users/sam/Software/bruce/examples/duotransits/402710280/mastDownload/HLSP/hlsp_tess-spoc_tess_phot_0000000402710280-s0066_tess_v1_tp/hlsp_tess-spoc_tess_phot_0000000402710280-s0066_tess_v1_lc.fits with expected size 1272960. [astroquery.query]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD - 2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'e-/s' did not parse as fits unit: At col 0, Unit 'e' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: UnitsWarning: 'pixels' did not parse as fits unit: At col 0, Unit 'pixels' not supported by the FITS standard. Did you mean pixel? If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found cached file /Users/sam/Software/bruce/examples/duotransits/402710280/mastDownload/HLSP/hlsp_qlp_tess_ffi_s0093-0000000402710280_tess_v01_llc/hlsp_qlp_tess_ffi_s0093-0000000402710280_tess_v01_llc.fits with expected size 673920. [astroquery.query]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: 'BJD-2457000, days' did not parse as fits unit: At col 0, Unit 'BJD' not supported by the FITS standard.  If this is meant to be a custom unit, define it with 'u.def_unit'. To have it recognized inside a file reader or other code, enable it with 'u.add_enabled_units'. For details, see https://docs.astropy.org/en/latest/units/combining_and_defining.html [astropy.units.core]\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "W :  2003\n",
      "Initial Chi-Sqaured : 3170.01 [red 52.83]\n",
      "Fitted parameters for TIC-402710280:\n",
      "t_zero : 2459384.6115788007\n",
      "radius_1 : 0.034869208168412075\n",
      "k : 0.04191276034649605\n",
      "b : 0.793705852570642\n",
      "Final Chi-Sqaured : 1122.34 [red 18.71]\n",
      "Initial Chi-Sqaured : 301.05 [red 5.28]\n",
      "Fitted parameters for TIC-402710280:\n",
      "t_zero : 2460838.1958112926\n",
      "radius_1 : 0.020715014791343633\n",
      "k : 0.028094613142058023\n",
      "b : 0.3368593054197144\n",
      "Final Chi-Sqaured : 289.33 [red 5.08]\n",
      "1 97 1 96.90561549946045 1453.5842324919067 15 15.141502421790696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/anaconda3/lib/python3.9/site-packages/bruce-1.0.0-py3.9-macosx-10.9-x86_64.egg/bruce/sampler/sampler.py:48: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  wt = 1. / (yerr**2 + jitter**2)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:19<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "def function(i):\n",
    "    \n",
    "    # Create the output dir (we'll use this as cache for the data too)\n",
    "    output_dir = os.getcwd() + '/{:}'.format(duos['tic_id'][i])\n",
    "    os.system('mkdir -p {:}'.format(output_dir))\n",
    "    \n",
    "    # Now load the TESS data (SPOC, QLP)\n",
    "    # We are not making our own here like TESSTPF, not yet anyway...\n",
    "    # for data_type\n",
    "    #   single_product -> all sectors together\n",
    "    #   per_sector -> list of per-sector lightcurves\n",
    "    #   northern_duos -> YEARS 2 and 4, then a list of other sectors \n",
    "    #   southern -> YEARS 1 and 3, then a list of other sectors (NOT IMPLEMENTED YET) \n",
    "    data, data_labels =  bruce.ambiguous_period.get_tess_data(duos['tic_id'][i], \n",
    "                                                              download_dir=output_dir, \n",
    "                                                              max_sector=np.inf, \n",
    "                                                              data_type='single_product')\n",
    "    \n",
    "\n",
    "    # OPTIONAL - Bin the data (get everything to 30-min cadence)\n",
    "    cadence = np.median(np.gradient(data.time))*1440 # Cadence in minutes\n",
    "    if cadence < 30: # Check if cadence < 30 min\n",
    "        t_bin, f_bin, fe_bin, _ = bruce.data.bin_data(data.time, data.flux, 0.5/24)\n",
    "        data.time = t_bin\n",
    "        data.flux = f_bin\n",
    "        data.flux_err = fe_bin\n",
    "    data.w = np.ones(len(data.flux))\n",
    "    \n",
    "    # Now we should sigma_clip, in case of QLP nonsense and outliers\n",
    "    time, flux, flux_err = [],[],[]\n",
    "    for seg in bruce.data.find_nights_from_data(data.time, dx_lim=0.1):\n",
    "        mask = ~sigma_clip(data.flux[seg], masked=True).mask\n",
    "        time.append(data.time[seg][mask])\n",
    "        flux.append(data.flux[seg][mask])\n",
    "    flux_err.append(data.flux_err[seg][mask])\n",
    "    data.time = time\n",
    "    data.flux = flux\n",
    "    data.flux_err = flux_err\n",
    "\n",
    "\n",
    "    # Flatten the data by SG filter, we need an odd kernel legth based on cadence\n",
    "    if cadence > 20 : window_length = 101 # For 30 minute data\n",
    "    elif cadence > 5 : window_length = 303# for 10 minute data \n",
    "    else : window_length = 2003 # for eventual 120-s data \n",
    "    sigmaclip=3\n",
    "\n",
    "    # We can cheat like this if we need to tailor a kernel to a specific target\n",
    "    # if duos['tic_id'][i]==130714841:\n",
    "    #     window_length = 503\n",
    "        \n",
    "    # Now flatten\n",
    "    data.flatten_data_old(window_length=window_length, sigmaclip=sigmaclip, dx_lim=0.1)\n",
    "\n",
    "    # Optional, save the data \n",
    "    data.write_data(output_dir + '/' +'TESS_DATA_{:}_{:}.txt'.format(0, data_labels))\n",
    "    fig, ax = data.plot_segments(dx_lim=0.5)\n",
    "    fig.savefig(output_dir + '/' + 'TESS_DATA_{:}_{:}.png'.format(0, data_labels))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # We will unpack now, (data with transits, and data without)\n",
    "    # We may need to change this for it to work properly (Sam is working on it)\n",
    "    # Its worth noting we can incorparate ground based data here too\n",
    "    # data_from_ground = bruce.ambiguous_period.mono_event.photometry_time_series(time, flux, flux_err, w = norm_model)\n",
    "    # Then this can go in data_other_sectors\n",
    "    data, data_other_sectors = data, []\n",
    "\n",
    "    ############################\n",
    "    # FIT EVENT 1\n",
    "    ############################\n",
    "    # Mask data and create the mono_event object\n",
    "    nmask = 3\n",
    "    mask1 = (data.time > (duos['t_zero_1'][i] - nmask*duos['width_1'][i])) &  (data.time < (duos['t_zero_1'][i] + nmask*duos['width_1'][i]))\n",
    "    data_event_1 = bruce.ambiguous_period.photometry_time_series(data.time[mask1], data.flux[mask1], data.flux_err[mask1], w=data.w[mask1]) #np.percentile(data.flux[mask1], 50)*np.ones(data.time[mask1].shape[0])\n",
    "    m1 = bruce.ambiguous_period.mono_event(duos['t_zero_1'][i], duos['width_1'][i], duos['depth_1'][i], data_event_1, name='TIC-{:}'.format(duos['tic_id'][i]), median_bin_size = None,convolve_bin_size = 3)\n",
    "\n",
    "    # Fit the event and report plots\n",
    "    fig_initial, ax_initial, fig_final, ax_final, return_data_1 = m1.fit_event_with_fixed_period(fit_period=30., plot=True, )\n",
    "    fig_initial.tight_layout()\n",
    "    fig_final.tight_layout()\n",
    "    fig_initial.savefig(output_dir + '/' + 'TIC-{:}_EVENT_1_INITIAL_INITIAL.png'.format(duos['tic_id'][i]))\n",
    "    fig_final.savefig(output_dir + '/' + 'TIC-{:}_EVENT_1_INITIAL_FINAL.png'.format(duos['tic_id'][i]))\n",
    "    plt.close(fig_initial); plt.close(fig_final)\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # FIT EVENT 2\n",
    "    ############################\n",
    "    # Mask data and create the mono_event object\n",
    "    mask2 = (data.time > (duos['t_zero_2'][i] - nmask*duos['width_2'][i])) &  (data.time < (duos['t_zero_2'][i] + nmask*duos['width_2'][i]))\n",
    "    data_event_2 = bruce.ambiguous_period.photometry_time_series(data.time[mask2], data.flux[mask2], data.flux_err[mask2], w=data.w[mask2]) #np.percentile(data.flux[mask2], 50)*np.ones(data.time[mask2].shape[0])\n",
    "    m2 = bruce.ambiguous_period.mono_event(duos['t_zero_2'][i], duos['width_2'][i], duos['depth_2'][i], data_event_2, name='TIC-{:}'.format(duos['tic_id'][i]), median_bin_size = None,convolve_bin_size = 3)\n",
    "\n",
    "    # Fit the event and report plots\n",
    "    fig_initial, ax_initial, fig_final, ax_final, return_data_2 = m2.fit_event_with_fixed_period(fit_period=30., plot=True, )\n",
    "    fig_initial.tight_layout()\n",
    "    fig_final.tight_layout()\n",
    "    fig_initial.savefig(output_dir + '/' + 'TIC-{:}_EVENT_2_INITIAL_INITIAL.png'.format(duos['tic_id'][i]))\n",
    "    fig_final.savefig(output_dir + '/' + 'TIC-{:}_EVENT_2_INITIAL_FINAL.png'.format(duos['tic_id'][i]))\n",
    "    plt.close(fig_initial); plt.close(fig_final)\n",
    "\n",
    "    # We are going to make a nice plot of the two events with their models\n",
    "    fig, ax = plt.subplots(1,2, gridspec_kw={'hspace' : 0, 'wspace' : 0}, figsize = (6.4, 3.8))\n",
    "    ax[0].errorbar(return_data_1[0], return_data_1[1], yerr=return_data_1[2], fmt='k.', alpha = 0.1)\n",
    "    ax[0].plot(return_data_1[3], return_data_1[4], c='orange')\n",
    "    ax[1].errorbar(return_data_2[0], return_data_2[1], yerr=return_data_2[2], fmt='k.', alpha = 0.1)\n",
    "    ax[1].plot(return_data_2[3], return_data_2[4], c='orange')\n",
    "    ax[1].set(yticks=[])\n",
    "    ylim1 = ax[0].get_ylim()\n",
    "    ylim2 = ax[1].get_ylim()\n",
    "    ylim = [min(ylim1[0],ylim2[0]), max(ylim1[1], ylim2[1])]\n",
    "    ax[0].set_ylim(ylim)\n",
    "    ax[1].set_ylim(ylim)\n",
    "    fig.supxlabel('Time from Transit [d]', fontsize=18, x=0.55, y = -0.005)\n",
    "    fig.supylabel('Flux', fontsize=18)\n",
    "    fig.suptitle(m2.name, y=0.95, x=0.55, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3', alpha=1.0), ha='center', fontsize=18)\n",
    "    plt.subplots_adjust(right=0.99, top=0.99, bottom=0.13)\n",
    "    fig.savefig('TIC-{:}_BOTH_EVENTS.png'.format(duos['tic_id'][i]))\n",
    "    plt.close(fig)\n",
    "\n",
    "    ########################################################\n",
    "    # CREATE THE AMBIGUOUS PERIOD OBJECT\n",
    "    ########################################################\n",
    "    p = bruce.ambiguous_period.ambiguous_period(data, events=[m1,m2], name='TIC-{:}'.format(duos['tic_id'][i]),\n",
    "                        median_bin_size = 2,convolve_bin_size = 2)\n",
    "\n",
    "    # Now mask and filter \n",
    "    p.mask_and_filter_events()\n",
    "\n",
    "    # Calculate aliases\n",
    "    # Do not use nsolutions_events here (that is superceeded later)\n",
    "    nsolutions_events = p.calcualte_aliases(dx_lim=0.03, min_period=15)\n",
    "\n",
    "    # Now calcualte whether we saw a transit by comparing the model to a flat line\n",
    "    delta_L_data = p.calcualte_data_delta_L(data)\n",
    "    delta_L_data_from_other_sectors_or_others = [p.calcualte_data_delta_L(j) for j in data_other_sectors]\n",
    "    p.delta_L = np.array([delta_L_data, *delta_L_data_from_other_sectors_or_others])\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    # Plot the aliases\n",
    "    ########################################################\n",
    "    fig, ax  = p.plot_aliases(phot_data=data_other_sectors, phot_data_labels=data_labels)\n",
    "    fig.savefig(output_dir + '/' + 'TIC-{:}_ALIASES.png'.format(duos['tic_id'][i]), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "        \n",
    "function(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec0760c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
